{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import pylab\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna, generic_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#template sequences: DNA sequences of your native template protein(s) that were the basis of an SSM library\n",
    "XCDP07 = 'GCGGACCCGAAAAAGGTCCTGGACAAAGCGAAAGACCGTGCGGAAAACGTTGTTCGTAAACTCAAGAAGGAACTCGAAGAACTGTACAAAGAGGCGCGTAAGCTGGACCTGACCCAGGAAATGCGTGATCGTATCCGCCTGGCGGCGATTGCAGCGCGTATCGCGGCGTTCGGTGACATCTTCCACGCGATCATGGAGGCGCTGGAGGAAGCGCGCAAGCTGAAAAAAGCGGGTCTGGTTAACTCTCAGCAGCTCGACGAACTCAAACGTCGTCTGGAAGAGCTCGATGAAGAAGCCGCACAACGTGCAGAAAAGCTGGGTAAAGAGTTTGAACTGAAACTGGAATACGGT'\n",
    "A2CDP06 = 'GCGGACCCGAAAAAAGTTCTGGATAAAGCGAAAGACGAAGCAGAAAACCGTGTTCGTGAACTGAAACAAAAACTCGAAGAACTCTACAAAGAAGCTCGTAAACTGGACCTGACCCAGGAAATGCGTCAGGAACTGGTGGACAAAGCGCGTGCGGCGTCTCTGCAGGCGTCTGGTGACATCTTCTACGCGATCCTGCGTGCGCTCGCGGAAGCGGAGAAACTCAAAAAAGCGGGTCTGGTTAACTCTCAGCAGCTGGACGAGCTCAAACGTCGTCTGGAGGAGCTGGCGGAAGAGGCGCGTCGTAAGGCGGAAAAACTGGGTGACGAATTTCGTCTGAAGCTGGAATACGGT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Paths to your data! My data is split across 2 separate MiSeq runs, since I didn't get enough counts in the first run. \n",
    "read1_1 = '/Users/dyounger/GoogleDrive/UW_Work/PAPER_YSA/Data/NGS/NGS_NaiveLib_Characterization/XCDP07_1_R1.fastq.gz'\n",
    "read2_1 = '/Users/dyounger/GoogleDrive/UW_Work/PAPER_YSA/Data/NGS/NGS_NaiveLib_Characterization/XCDP07_1_R2.fastq.gz'\n",
    "read1_2 = '/Users/dyounger/GoogleDrive/UW_Work/PAPER_YSA/Data/NGS/NGS_NaiveLib_Characterization/XCDP07_2_R1.fastq.gz'\n",
    "read2_2 = '/Users/dyounger/GoogleDrive/UW_Work/PAPER_YSA/Data/NGS/NGS_NaiveLib_Characterization/XCDP07_2_R2.fastq.gz'\n",
    "\n",
    "#define the template for this library\n",
    "TEMPLATE = XCDP07\n",
    "\n",
    "#give a name for the output file!\n",
    "output_name = 'XCDP07' + '_BarcodeLibrary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define reverse complement function\n",
    "alt_map = {'ins':'0'}\n",
    "complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'} \n",
    "def reverse_complement(seq):    \n",
    "    for k,v in alt_map.items():\n",
    "        seq = seq.replace(k,v)\n",
    "    bases = list(seq) \n",
    "    bases = reversed([complement.get(base,base) for base in bases])\n",
    "    bases = ''.join(bases)\n",
    "    for k,v in alt_map.items():\n",
    "        bases = bases.replace(v,k)\n",
    "    return bases\n",
    "#Defines function that just reverses, no complement.\n",
    "nocomplement = {'zzz': 'zzz'} \n",
    "def reverse(qual):    \n",
    "    for k,v in alt_map.items():\n",
    "        qual = qual.replace(k,v)\n",
    "    scores = list(qual) \n",
    "    scores = reversed([nocomplement.get(score,score) for score in scores])\n",
    "    scores = ''.join(scores)\n",
    "    for k,v in alt_map.items():\n",
    "        scores = scores.replace(v,k)\n",
    "    return scores \n",
    "\n",
    "#Define function for finding the frequency of each base in a group and finding the consensus sequence\n",
    "def find_consensus_plus_aa(group):\n",
    "    \n",
    "    #Set up info about template\n",
    "    TEMPLATE_dna = Seq(TEMPLATE)\n",
    "    TEMPLATE_aa = str(TEMPLATE_dna.translate())    \n",
    "    dna_length = len(TEMPLATE)\n",
    "    \n",
    "    list_of_DNA_sequences = group\n",
    "    #First construct a frequency matrix for each base and N\n",
    "    n = max([len(dna) for dna in list_of_DNA_sequences])\n",
    "    frequency_matrix = {base: np.zeros(n, dtype=np.int)\n",
    "                        for base in 'ACGTN'}\n",
    "    for dna in list_of_DNA_sequences:\n",
    "        for index, base in enumerate(dna):\n",
    "            frequency_matrix[base][index] += 1\n",
    "    #Next, choose consensus based on base with highest frequency at each location\n",
    "    consensus = ''\n",
    "    for i in range(dna_length):  # loop over positions in string\n",
    "        max_freq = -1            # holds the max freq. for this i\n",
    "        max_freq_base = None     # holds the corresponding base\n",
    "        for base in 'ACGT':\n",
    "            if frequency_matrix[base][i] > max_freq:\n",
    "                max_freq = frequency_matrix[base][i]\n",
    "                max_freq_base = base\n",
    "            elif frequency_matrix[base][i] == max_freq:\n",
    "                max_freq_base = 'N' # more than one base as max\n",
    "        consensus += max_freq_base  # add new base with max freq \n",
    "    \n",
    "    consensus_dna = Seq(consensus)\n",
    "    consensus_aa = str(consensus_dna.translate())         \n",
    "        \n",
    "    #Find the size of this group    \n",
    "    group_size = size(group) \n",
    "    #find the number of unknowns and mismatches\n",
    "    unknowns = consensus_aa.count('X')        \n",
    "    mismatches = sum (consensus_aa[i] != TEMPLATE_aa[i] for i in range(len(TEMPLATE_aa))) - unknowns\n",
    "\n",
    "    #Get the summary info for single point mutants (position and mutation)\n",
    "    mutation = np.nan\n",
    "    position = np.nan\n",
    "\n",
    "    if mismatches == 1:\n",
    "        for i in range(len(TEMPLATE_aa)):\n",
    "            if consensus_aa[i] != TEMPLATE_aa[i]:\n",
    "                position = i+1\n",
    "                mutation = consensus_aa[i]\n",
    "    if mismatches == 0:\n",
    "        position = 0\n",
    "        mutation = '-'\n",
    "    \n",
    "    #return important variables\n",
    "    return [consensus_aa, group_size, mismatches, unknowns, mutation, position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab all of the sequencing data for read1 and read2\n",
    "seqsF = []\n",
    "seqsR = []\n",
    "qualsF = []\n",
    "qualsR = []\n",
    "countF = 0\n",
    "countR = 0\n",
    "with gzip.open(read1_1) as f2:\n",
    "    while True:\n",
    "        headerF =  f2.readline()[:-1]\n",
    "        seqF =  f2.readline()[:-1]\n",
    "        strandF =  f2.readline()[:-1]\n",
    "        qualF =  f2.readline()[:-1]\n",
    "        countF = countF + 1\n",
    "        if len(headerF)==0: \n",
    "            break\n",
    "        seqsF.append(seqF)\n",
    "        qualsF.append(qualF)\n",
    "with gzip.open(read2_1) as f2:\n",
    "    while True:\n",
    "        headerR =  f2.readline()[:-1]\n",
    "        seqR =  f2.readline()[:-1]\n",
    "        strandR =  f2.readline()[:-1]\n",
    "        qualR =  f2.readline()[:-1]\n",
    "        countR = countR + 1\n",
    "        if len(headerR)==0: \n",
    "            break\n",
    "        seqsR.append(seqR)\n",
    "        qualsR.append(qualR)  \n",
    "seqs2F = []\n",
    "seqs2R = []\n",
    "quals2F = []\n",
    "quals2R = []\n",
    "count2F = 0\n",
    "count2R = 0        \n",
    "with gzip.open(read1_2) as f2:\n",
    "    while True:\n",
    "        headerF =  f2.readline()[:-1]\n",
    "        seqF =  f2.readline()[:-1]\n",
    "        strandF =  f2.readline()[:-1]\n",
    "        qualF =  f2.readline()[:-1]\n",
    "        count2F = count2F + 1\n",
    "        if len(headerF)==0: \n",
    "            break\n",
    "        seqs2F.append(seqF)\n",
    "        quals2F.append(qualF)        \n",
    "with gzip.open(read2_2) as f2:\n",
    "    while True:\n",
    "        headerR =  f2.readline()[:-1]\n",
    "        seqR =  f2.readline()[:-1]\n",
    "        strandR =  f2.readline()[:-1]\n",
    "        qualR =  f2.readline()[:-1]\n",
    "        count2R = count2R + 1\n",
    "        if len(headerR)==0: \n",
    "            break\n",
    "        seqs2R.append(seqR)\n",
    "        quals2R.append(qualR)\n",
    "        \n",
    "#Combine data from both sequencing runs:\n",
    "seqsF = seqsF + seqs2F\n",
    "seqsR = seqsR + seqs2R\n",
    "qualsF = qualsF + quals2F\n",
    "qualsR = qualsR + quals2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083834\n"
     ]
    }
   ],
   "source": [
    "#Get dataframes in order and only keep the sequences that have correct constant regions\n",
    "#convert to dataframes and reverse complement read2\n",
    "read1=pd.DataFrame(data=seqsF,columns=['read1'])\n",
    "read2=pd.DataFrame(data=seqsR,columns=['read2']).applymap(reverse_complement)\n",
    "#Join into a single dataframe\n",
    "df=read1.join(read2)\n",
    "#only keep the sequences with the correct constant regions\n",
    "df=df[df.read1.str.slice(19,34) == 'TCGGCTAGCCATATG']\n",
    "df=df[df.read2.str.slice(185,200) == 'GGGGCGGATCCGAAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate adjustment for total length for stitching parts together\n",
    "adjust = len(TEMPLATE)-76\n",
    "\n",
    "#Separate sequences: SSM ends, overlaps, and barcodes. For each, reset index.\n",
    "SSMseqPart1=pd.DataFrame(data=df.read1.str.slice(34,adjust),columns=['read1'])\n",
    "df_part1=pd.DataFrame(data=SSMseqPart1.rename(columns={\"read1\": \"part1\"}),columns=['part1'])\n",
    "df_part1=df_part1.reset_index()\n",
    "del df_part1['index']\n",
    "\n",
    "SSMseqPart3=pd.DataFrame(data=df.read2.str.slice(68,178),columns=['read2'])\n",
    "df_part3=pd.DataFrame(data=SSMseqPart3.rename(columns={\"read2\": \"part3\"}),columns=['part3'])\n",
    "df_part3=df_part3.reset_index()\n",
    "del df_part3['index']\n",
    "\n",
    "BARCODE=pd.DataFrame(data=df.read2.str.slice(257,267),columns=['read2'])\n",
    "BARCODE=BARCODE.reset_index()\n",
    "del BARCODE['index']\n",
    "\n",
    "#make a copy of barcodes for easier processing after grouping\n",
    "barcode2=BARCODE.copy()\n",
    "barcode2.columns = ['barcodes']\n",
    "\n",
    "#put everything into a nice new dataframe with fully assembled sequences and a defined barcode\n",
    "df_all = pd.DataFrame()\n",
    "df_all=df_part1.join(df_part3)\n",
    "df_final = pd.DataFrame()\n",
    "df_final['sequence']=df_all[['part1','part3']].apply(lambda x:''.join(x), axis=1)\n",
    "df_final=df_final.join(BARCODE)\n",
    "df_final=df_final.join(barcode2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add a dummy template sequence for every possible barcode to the dataframe\n",
    "#Basically, this acts as a tie breaker for cases where there are only 2 in a group\n",
    "bases=['A','T','C','G']\n",
    "all_possible_barcodes=[''.join(i) for i in itertools.product(bases, repeat=10)]\n",
    "all_possible_barcodes2 = pd.DataFrame(data=all_possible_barcodes,columns=['read2'])\n",
    "all_possible_barcodes3 = pd.DataFrame(data=all_possible_barcodes,columns=['barcodes'])\n",
    "\n",
    "TEMPLATE_obj = [TEMPLATE]\n",
    "template_list = TEMPLATE_obj * len(all_possible_barcodes2)\n",
    "template_list = pd.DataFrame(data=template_list,columns=['sequence'])\n",
    "no_mutations=template_list.join(all_possible_barcodes2)\n",
    "no_mutations=no_mutations.join(all_possible_barcodes3)\n",
    "\n",
    "result=pd.concat([df_final,no_mutations])\n",
    "result=result.reset_index()\n",
    "del result['index']\n",
    "\n",
    "df_final = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the consensus sequence for each barcode. Start by only looking at sequences with 3+ barcodes\n",
    "#filter out any sequences that have only 1 or 2 barcodes\n",
    "filtered = df_final[df_final.groupby('read2').read2.transform(len) > 2]\n",
    "#group sequences by their barcode\n",
    "grouped = filtered.groupby('read2')\n",
    "#find consensus AA sequence for each group\n",
    "consensus_AA = grouped.sequence.apply(find_consensus_plus_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Assemble a dataframe from the grouped data:\n",
    "#Build the summary dataframe\n",
    "summary_AA = pd.DataFrame(consensus_AA.tolist(),columns=['sequence','group_size','mismatches','unknowns','mutation','position'])\n",
    "\n",
    "#Add the barcodes to the dataframe\n",
    "group_barcode = grouped.barcodes.last()\n",
    "group_barcode = group_barcode.to_frame()\n",
    "group_barcode = group_barcode.reset_index()\n",
    "del group_barcode['read2']\n",
    "summary_AA['barcode']=group_barcode\n",
    "\n",
    "#only keep \"clean\" barcodes (0 or 1 mismatch, no unknowns)\n",
    "summary_AA = summary_AA[summary_AA.mismatches < 2]\n",
    "summary_AA = summary_AA[summary_AA.unknowns == 0]\n",
    "\n",
    "#Fix indexing of the summary dataframe\n",
    "summary_AA=summary_AA.reset_index()\n",
    "#get rid of unneccessary columns\n",
    "del summary_AA['index']\n",
    "del summary_AA['mismatches']\n",
    "del summary_AA['unknowns']\n",
    "del summary_AA['sequence']\n",
    "\n",
    "summary_AA = summary_AA.sort_values(['position','mutation','group_size'],ascending=[True,True,True])\n",
    "summary_AA=summary_AA.reset_index()\n",
    "del summary_AA['index']\n",
    "\n",
    "summary_AA['pos'] = summary_AA['position']\n",
    "summary_AA['pos']=summary_AA['pos'].astype(int).astype(str)\n",
    "\n",
    "summary_AA['combined'] = summary_AA['mutation']+summary_AA['pos']\n",
    "\n",
    "#print summary_AA\n",
    "#Output file for reading into analysis script!\n",
    "summary_AA.to_csv(output_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique mutatons\n",
      "1417\n",
      "percent of library coverage\n",
      "60\n",
      "2340\n"
     ]
    }
   ],
   "source": [
    "#Other information that may be useful: I was only looking at a partial SSM library, but I still wanted to know\n",
    "#what percent of the total SSM space I was covering with this library\n",
    "\n",
    "#How many unique mutations are present in the library?\n",
    "print \"Total possible variants in\"\n",
    "print len(TEMPLATE)*20/3\n",
    "print \"unique mutatons\"\n",
    "print len(set(summary_AA['combined']))\n",
    "print \"percent of library coverage\"\n",
    "print 100*len(set(summary_AA['combined']))/(len(TEMPLATE)*20/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Want to make a histogram of group sizes?\n",
    "#summary_AA\n",
    "#summary_AA['group_size'].hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
